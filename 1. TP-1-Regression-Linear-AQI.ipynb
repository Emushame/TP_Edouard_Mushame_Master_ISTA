{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87fdbbd4-4ffc-4258-a2be-9d9709ebbb6b",
   "metadata": {},
   "source": [
    "# 1. Importation des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749442f-ccb3-4e9e-9c60-3b13c3a886ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires pour l'analyse des données, la visualisation, le prétraitement, et la modélisation.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c04ce-8e80-41b1-8d41-9d51421f8274",
   "metadata": {},
   "source": [
    "# 2. Charger les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a5a562-de06-4132-acc6-842fb7f28859",
   "metadata": {},
   "source": [
    "## 2.1. Description de la source de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016622c-3a54-4a17-8b6b-8753f7ff91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les données proviennent d'un fichier CSV (delhi_aqi.csv) contenant des mesures horaires de la qualité de l'air à Delhi.\n",
    "# Les colonnes incluent des mesures de polluants tels que CO, NO, NO2, O3, SO2, PM2.5, PM10, NH3, ainsi que la date et l'heure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34b9bab-ad59-4b16-a613-75c3d05dfc21",
   "metadata": {},
   "source": [
    "## 2.2. Description des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8a1a7-43e6-4ed0-8041-7972aa701d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données dans un DataFrame Pandas.\n",
    "# Afficher les premières lignes pour comprendre la structure.\n",
    "# Vérifier les informations de base (types de données, valeurs manquantes, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29132c-3f9e-4c18-a228-e7fc10b38379",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/delhi_aqi.csv')\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb68e855-ba72-4879-adf3-2c9217c73c54",
   "metadata": {},
   "source": [
    "# 3. Analyse des données (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811435cf-cec0-4efc-a380-a2cc398592fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data['so2'], kde=True)\n",
    "plt.title('Distribution de SO2')\n",
    "plt.show()\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "plt.plot(data['date'], data['so2'])\n",
    "plt.title('Tendance de SO2 au fil du temps')\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Matrice de corrélation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c3034-9bad-4738-be55-a0974f39f0f6",
   "metadata": {},
   "source": [
    "# 4. Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a6faf-7bc2-43bb-8ec1-f7898d3b955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des caractéristiques temporelles\n",
    "\n",
    "data['hour'] = data['date'].dt.hour\n",
    "data['day'] = data['date'].dt.day\n",
    "data['month'] = data['date'].dt.month\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data.drop(columns=['date']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d598cd8-831e-4cfc-aa8e-8a1a7b002d5e",
   "metadata": {},
   "source": [
    "# 5. Division de données (Train et Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8edb78-80de-4b35-94b6-2ccddb2f7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les données\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data.drop(columns=['date']))\n",
    "\n",
    "# Convertir en DataFrame avec les noms de colonnes\n",
    "column_names = data.drop(columns=['date']).columns\n",
    "scaled_data_df = pd.DataFrame(scaled_data, columns=column_names)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X = scaled_data_df.drop(columns=['so2'])  # Features\n",
    "y = scaled_data_df['so2']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17975386-b6f9-4f4d-9c38-dbb8a3d1f144",
   "metadata": {},
   "source": [
    "# 6. Construire le modele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aab794-49e1-4014-8862-852fce64c6ae",
   "metadata": {},
   "source": [
    "## 6.1. Construire le modele Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c0c1a-c251-4bef-9932-9f0e07468318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous allons utiliser un modèle de régression (Random Forest), Entraîner le modèle sur les données d'entraînement.\n",
    "# Puis evaluer les performances sur les données de test.\n",
    "\n",
    "model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba392e38-0d1a-46e2-a0da-e4b956f64af0",
   "metadata": {},
   "source": [
    "## 6.2. Construire le modele Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdfb094-aba2-45cd-8670-81a7ad6a650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici nous allons créer un modèle de réseau de neurones avec TensorFlow/Keras.\n",
    "# Entraîner le modèle sur les données d'entraînement.\n",
    "# Évaluer les performances sur les données de test\n",
    "\n",
    "model_dl = Sequential()\n",
    "model_dl.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model_dl.add(Dense(32, activation='relu'))\n",
    "model_dl.add(Dense(1, activation='linear'))\n",
    "model_dl.compile(optimizer='adam', loss='mse')\n",
    "model_dl.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "y_pred_dl = model_dl.predict(X_test)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred_dl)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ec715-545d-413d-9d18-9fa889a3e7b1",
   "metadata": {},
   "source": [
    "# 7. Visualiser l'evolution de l'entrainement du réseau de neurone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19639645-4f7f-4857-9f43-e2bbf2017d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les prédictions par rapport aux valeurs réelles\n",
    "\n",
    "plt.scatter(y_test, y_pred_rf, label='Random Forest')\n",
    "plt.scatter(y_test, y_pred_dl, label='Deep Learning')\n",
    "plt.xlabel('Valeurs réelles')\n",
    "plt.ylabel('Prédictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9105985-c889-45ad-8d0d-531ff4c2d248",
   "metadata": {},
   "source": [
    "# 8. Evaluer le modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c447dc-85dc-48e8-a555-282ca3fe373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparons maintenant les performances des modèles (Machine Learning vs Deep Learning).\n",
    "# Analyser les erreurs RMSE.\n",
    "\n",
    "# Compiler le modèle avec une métrique supplémentaire\n",
    "model_dl.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entraîner le modèle et capturer l'historique\n",
    "history = model_dl.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Visualiser la perte\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.plot(epochs, train_loss, 'bo-', label='Perte d\\'entraînement')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Perte de validation')\n",
    "plt.title('Évolution de la perte pendant l\\'entraînement')\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Perte')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualiser l'erreur absolue moyenne (MAE)\n",
    "train_mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "plt.plot(epochs, train_mae, 'bo-', label='MAE d\\'entraînement')\n",
    "plt.plot(epochs, val_mae, 'ro-', label='MAE de validation')\n",
    "plt.title('Évolution de l\\'erreur absolue moyenne (MAE)')\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56cc315-1d5d-4cfd-a638-6dd1dce964cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:edouard_env]",
   "language": "python",
   "name": "conda-env-edouard_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
